Building DAG of jobs...
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	ensembl_api
	1	report
	1	variant_api
	1	workflow
	5

rule variant_api:
    output: variant_info.txt
    jobid: 3

Finished job 3.
1 of 5 steps (20%) done

rule ensembl_api:
    input: variant_info.txt
    output: ensembl_application.json
    jobid: 2

Finished job 2.
2 of 5 steps (40%) done

rule workflow:
    output: workflow.svg
    jobid: 4

snakemake --dag all | dot -Tsvg > workflow.svg
Error in rule workflow:
    jobid: 4
    output: workflow.svg

RuleException:
CalledProcessError in line 35 of /home/minor-g2/Documents/Awan_Mel/API_course_11/Snakefile:
Command ' set -euo pipefail;  snakemake --dag all | dot -Tsvg > workflow.svg ' returned non-zero exit status 127.
  File "/home/minor-g2/Documents/Awan_Mel/API_course_11/Snakefile", line 35, in __rule_workflow
  File "/usr/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Removing output files of failed job workflow since they might be corrupted:
workflow.svg
Will exit after finishing currently running jobs.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2019-06-07T161543.734825.snakemake.log
